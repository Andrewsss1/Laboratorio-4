Cerchiamo quel modelo (forma funzionale) che è in grado di riprodurre i dati che abbiamo misurato
Quello che ci interessa è l'accuratezza di queste W che è il vettore che contiene i parametri e sono i parametri del modello. Nel caso dell'approccio classico vogliamo capire qual è la migliore stima dei parametri
Nel caso del machine learning. Ci interessa quel vettore che massimizza la probabilità per X dato W. 
-------------

quando avete un modello molto complesso avete una bassa varianza ma un bias alto. Il bias è la distanza tra il vostro modello (o media di modelli) e il modello vero. La variance è lo spread dei modelli. 
Qua avete bassa variance e alto bias
Vedete che in un modello ad alta complessità bassa var. e alto bias.
Vi siete giocati la verità
Se voi prendete tutti i modelli che hanno alta var. e basso bias andate ad indovinare qual è il modello vero. 
Il bias si riduce ma la variance aumenta. 
Due trasparenze che continuano questo discorso rendendolo quantitativo. Quello che abbiamo imparato è che l'errore che commettiamo è la somma di due pezzi, uno si chiamaa bias e non può scendere sotto un valore tot e poi c'è la variance che invece possiamo giostrarcelo. 
Quando si parla di machine learning bisogna scegliere il trad off: scegliere il modello che crea il gisuto compromesso tra questi due parametri. Si parla di decomposizione bias-variance. Ci fermiamo e ci vediamo domani alle 11. 